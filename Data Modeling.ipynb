{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "\n",
    "In the data modeling part, the purpose of the model is predictive. In other words, the target is to fit a model that given student information as collected in the data set, would be able to predcit the academic performace of the student, namely G3 (final grade) in this dataset. \n",
    "\n",
    "\n",
    "### Outcome Variable Selection and Imputation\n",
    "\n",
    "In the original paper, variables highly correlated with G3, namely G1 and G2 are also included in the training data set. Since these two variables are intrinsically same measurement as the output variable G3 is, it is not informative to use G1 and G2 to predict G3. For the purpose of more meaningful investigation into the dateset, G1 and G2 are dropped.\n",
    "\n",
    "In the original paper, three approaches are used to measure the G3 grade:  \n",
    "1. Binary classification – pass if G3≥10, else fail;\n",
    "2. 5-Level classification – based on the Erasmus grade conversion system (Table 2);\n",
    "3. Regression – the G3 value (numeric output between 0 and 20).\n",
    "\n",
    "In the preliminary tryout of the models, the accuracy of the models based on latter two approaches are significantly lower than benchmark of the distribution of G3 itself. i.e. the accuracy of predicting a student gets an A is smaller than blindly guessing that the student gets an A. The drop of accuracy compared with the original paper is due to the drop of G1 and G2. \n",
    "Therefore, the G3 is changed into a binary categorical variable (\"Pass\" or \"Fail\").\n",
    "\n",
    "\n",
    "### Data Selection\n",
    "\n",
    "Although there are 382 students from both data sets, it is notable that students' performance vary in different classes as explored in data exploratory section. Therefore, the two datasets are used seperately in training and prediction. For each method of classification, the model is seperately tuned fitted, and tested for accuracy on each of the two data sets.  \n",
    "\n",
    "\n",
    "### Model Selection and Fitting Procedure\n",
    "\n",
    "Three classfication methods are tried in the modeling part:\n",
    "1. Support Vector Machine\n",
    "2. Tree model\n",
    "3. Random Forest\n",
    "\n",
    "The procedure of fitting a model on a dataset is as following:\n",
    "1. The data set is seperated into 70% and 30% for training and testing.\n",
    "2. Cross validation is conducted over the training data to perform grid search for the purpose of tuning the model.\n",
    "3. The tuned model is tested over the testing data, and metrics such as accuracy and classification report are used to show the predictive performance of the model.\n",
    "4. After conducting a total of 6 model fittings (3 methods over 2 datasets each time), the models are tested by 5-fold cross validation over the whole data set for a comparision of performacec between each model over each data set.\n",
    "\n",
    "It is notable that the tree model and random forest model output different best tuning parameters each time given different random states. So for these two models, the \"further tuning\" was applying a more comprehensive grid according to the result of 10 runs over original grid. Given the huge amount of time it takes to train the model, only the final grid parameters are shown and used in this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main Code Chunk of the paper\n",
    "1. Modules and functions import\n",
    "2. Functions written for models\n",
    "'''\n",
    "\n",
    "#modules and functions needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def find_accuracy(model, fold, X, y):\n",
    "    '''\n",
    "    Finds the accuracy of a model over the whole data set.\n",
    "    '''\n",
    "    scores = cross_val_score(model, X, y, cv=fold)\n",
    "    print(\"Accuracy based on %i-fold cross validation is: %0.3f (+/- %0.3f)\"\n",
    "          % (int(fold), scores.mean(), scores.std() * 2))\n",
    "    result = \"%0.3f (+/- %0.3f)\"% (scores.mean(), scores.std() * 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def SVC_Grid_Search(X, y, c_vals, gamma_vals, rs=22, testSize = 0.3):\n",
    "    '''\n",
    "    SVC model, parameters to tune are C and gamma\n",
    "    '''\n",
    "    #1. Split data into 70 30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=testSize, random_state=rs)\n",
    "    \n",
    "    \n",
    "    #2. CV for tuning\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             ('SVM', SVC())]\n",
    "    pipeline = Pipeline(steps)\n",
    "    parameters = {'SVM__C':c_vals,\n",
    "                  'SVM__gamma':gamma_vals}\n",
    "    cv = GridSearchCV(pipeline, parameters, cv=10)\n",
    "    cv.fit(X_train, y_train)\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "    #3. Compute and print metrics\n",
    "    print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "    best = cv.best_estimator_\n",
    "    return best\n",
    "\n",
    "\n",
    "def Tree_Grid_Search(X, y, depth, feature, minleaf, rs=22, testSize = 0.3):\n",
    "    '''\n",
    "    Tree model, parameters to tune are max_depth, \n",
    "    max_features and min_samples_leaf\n",
    "    '''\n",
    "    #1. Split data into 70 30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=testSize, random_state=rs)\n",
    "\n",
    "    #2. CV for tuning\n",
    "    param = {\"max_depth\": depth,\n",
    "             \"max_features\": feature,\n",
    "             \"min_samples_leaf\": minleaf}\n",
    "    tree = DecisionTreeClassifier(random_state=rs)\n",
    "    tree_cv = RandomizedSearchCV(tree, param, cv=5, random_state=rs)\n",
    "    tree_cv.fit(X_train,y_train)\n",
    "    tree_pred = tree_cv.predict(X_test)\n",
    "\n",
    "\n",
    "    #3. Compute and print metrics\n",
    "    print(\"Accuracy: {}\".format(tree_cv.score(X_test, y_test)))\n",
    "    print(classification_report(y_test, tree_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(tree_cv.best_params_))\n",
    "    best = tree_cv.best_estimator_\n",
    "    return best\n",
    "\n",
    "\n",
    "def RF_Grid_Search(X, y, ne, depth, feature, ms, rs=22, testSize = 0.3):\n",
    "    '''\n",
    "    Random forest model, parameters to tune are \n",
    "    n_estimators, max_depth, max_features\n",
    "    min_samples_split, and bootstrap\n",
    "    '''\n",
    "    #1. Split data into 70 30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=testSize, random_state=rs)\n",
    "    \n",
    "    #2. CV for tuning\n",
    "    param_dist = {\"n_estimators\": ne,\n",
    "                  \"max_depth\": depth,\n",
    "                  \"max_features\": feature,\n",
    "                  \"min_samples_split\": ms,\n",
    "                  \"bootstrap\": [True, False]}\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=rs)\n",
    "    rf_cv = RandomizedSearchCV(rf, param_dist, cv=5, random_state=rs)\n",
    "    rf_cv.fit(X_train,y_train)\n",
    "    rf_pred = rf_cv.predict(X_test)\n",
    "    \n",
    "    #3. Compute and print metrics\n",
    "    print(\"Accuracy: {}\".format(rf_cv.score(X_test, y_test)))\n",
    "    print(classification_report(y_test, rf_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(rf_cv.best_params_))\n",
    "    best = rf_cv.best_estimator_\n",
    "    return best\n",
    "\n",
    "def find_accuracy_and_cr(model, fold, X, y):\n",
    "    '''\n",
    "    Finds the accuracy of a model over the whole data set.\n",
    "    Also outputs the classification report.\n",
    "    '''\n",
    "    scores = cross_val_score(model, X, y, cv=fold)\n",
    "    print(\"Accuracy based on %i-fold cross validation is: %0.3f (+/- %0.3f)\"\n",
    "          % (int(fold), scores.mean(), scores.std() * 2))\n",
    "    result = \"%0.3f (+/- %0.3f)\"% (scores.mean(), scores.std() * 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pd.read_csv('student-mat.csv')\n",
    "por = pd.read_csv('student-por.csv')\n",
    "def data_reform(df):\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.iloc[i, 15] < 10:\n",
    "            df.iloc[i, 15] = \"Fail\"\n",
    "        else:\n",
    "            df.iloc[i, 15] = \"Pass\"\n",
    "    return df\n",
    "\n",
    "mat = data_reform(mat)\n",
    "por = data_reform(por)\n",
    "\n",
    "Xmat = mat.drop(columns=['G1', 'G2', 'G3'])\n",
    "ymat = mat.G3\n",
    "Xpor = por.drop(columns=['G1', 'G2', 'G3'])\n",
    "ypor = por.G3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265 130\n",
      "0.6708860759493671\n",
      "0.3291139240506329\n"
     ]
    }
   ],
   "source": [
    "print(sum(ymat==\"Pass\"), sum(ymat==\"Fail\"))\n",
    "print(sum(ymat==\"Pass\")/len(ymat))\n",
    "print(sum(ymat==\"Fail\")/len(ymat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 100\n",
      "0.8459167950693375\n",
      "0.15408320493066255\n"
     ]
    }
   ],
   "source": [
    "print(sum(ypor==\"Pass\"), sum(ypor==\"Fail\"))\n",
    "print(sum(ypor==\"Pass\")/len(ypor))\n",
    "print(sum(ypor==\"Fail\")/len(ypor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models over Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7310924369747899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.60      0.18      0.27        34\n",
      "       Pass       0.74      0.95      0.84        85\n",
      "\n",
      "avg / total       0.70      0.73      0.67       119\n",
      "\n",
      "Tuned Model Parameters: {'SVM__C': 10, 'SVM__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#preliminary C and gama\n",
    "cm1 = [1, 10, 100]\n",
    "gm1 = [1, 0.1, 0.01, 0.001]\n",
    "svm1 = SVC_Grid_Search(Xmat, ymat, cm1, gm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7310924369747899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.60      0.18      0.27        34\n",
      "       Pass       0.74      0.95      0.84        85\n",
      "\n",
      "avg / total       0.70      0.73      0.67       119\n",
      "\n",
      "Tuned Model Parameters: {'SVM__C': 7, 'SVM__gamma': 0.0015}\n"
     ]
    }
   ],
   "source": [
    "#Closer look at C and gama\n",
    "cm2 = [7, 8, 9, 10,15,20]\n",
    "gm2 = [0.0001,0.0008,0.0009,0.001, 0.0012, 0.0015]\n",
    "svm2 = SVC_Grid_Search(Xmat, ymat, cm2, gm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second tuned model does not have an improvement in the accuracy. In order to determine if the tuning has a tendancy of over fitting, a 5-fold cross validation is coducted for the estimation of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first tuned SVM model over math data: \n",
      "Accuracy based on 5-fold cross validation is: 0.706 (+/- 0.063)\n",
      "For the second tuned SVM model over math data: \n",
      "Accuracy based on 5-fold cross validation is: 0.706 (+/- 0.063)\n"
     ]
    }
   ],
   "source": [
    "print(\"For the first tuned SVM model over math data: \")\n",
    "sm1 = find_accuracy(svm1, 5, Xmat, ymat)\n",
    "print(\"For the second tuned SVM model over math data: \")\n",
    "sm2 = find_accuracy(svm2, 5, Xmat, ymat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies are the same, indicating that the original model is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7226890756302521\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.57      0.12      0.20        34\n",
      "       Pass       0.73      0.96      0.83        85\n",
      "\n",
      "avg / total       0.69      0.72      0.65       119\n",
      "\n",
      "Tuned Model Parameters: {'min_samples_leaf': 9, 'max_features': 1, 'max_depth': 38}\n",
      "Accuracy based on 5-fold cross validation is: 0.646 (+/- 0.053)\n"
     ]
    }
   ],
   "source": [
    "dt1 = np.arange(1,42)\n",
    "ft1 = np.arange(1,21)\n",
    "mt1 = np.arange(1,21)\n",
    "tree1 = Tree_Grid_Search(Xmat, ymat, dt1, ft1, mt1, rs=22)\n",
    "tm1 = find_accuracy(tree1, 5, Xmat, ymat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6722689075630253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.53      0.20      0.29        40\n",
      "       Pass       0.69      0.91      0.79        79\n",
      "\n",
      "avg / total       0.64      0.67      0.62       119\n",
      "\n",
      "Tuned Model Parameters: {'n_estimators': 500, 'min_samples_split': 16, 'max_features': 5, 'max_depth': 8, 'bootstrap': False}\n",
      "Accuracy based on 5-fold cross validation is: 0.699 (+/- 0.076)\n"
     ]
    }
   ],
   "source": [
    "nr1 = [10, 100, 200, 500, 1000]\n",
    "dr1 = np.arange(1,42)\n",
    "fr1 = np.arange(1,21)\n",
    "mr1 = np.arange(2,21)\n",
    "rf1 = RF_Grid_Search(Xmat, ymat, nr1, dr1, fr1, mr1, rs=28)\n",
    "rm1 = find_accuracy(rf1, 5, Xmat, ymat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models over Portuguese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8358974358974359\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.39      0.25      0.30        28\n",
      "       Pass       0.88      0.93      0.91       167\n",
      "\n",
      "avg / total       0.81      0.84      0.82       195\n",
      "\n",
      "Tuned Model Parameters: {'SVM__C': 10, 'SVM__gamma': 0.01}\n",
      "Accuracy based on 5-fold cross validation is: 0.809 (+/- 0.166)\n"
     ]
    }
   ],
   "source": [
    "svm3 = SVC_Grid_Search(Xpor, ypor, cm1, gm1)\n",
    "sp3 = find_accuracy(svm3, 5, Xpor, ypor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841025641025641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.41      0.25      0.31        28\n",
      "       Pass       0.88      0.94      0.91       167\n",
      "\n",
      "avg / total       0.81      0.84      0.82       195\n",
      "\n",
      "Tuned Model Parameters: {'SVM__C': 5, 'SVM__gamma': 0.01}\n",
      "Accuracy based on 5-fold cross validation is: 0.809 (+/- 0.155)\n"
     ]
    }
   ],
   "source": [
    "cm3 = [4, 5,10,15,20]\n",
    "gm3 = [0.007,0.008,0.009,0.01, 0.012, 0.015]\n",
    "svm4 = SVC_Grid_Search(Xpor, ypor, cm3, gm3)\n",
    "sp4 = find_accuracy(svm4, 5, Xpor, ypor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The further-tuned model seems to have a slightly better performance given better accuracy on testing, and smaller fluctuation in cross validation. To decide which model to adopt, a 10-fold cross validation is applied on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first tuned SVM model over Portuguese data: \n",
      "Accuracy based on 10-fold cross validation is: 0.820 (+/- 0.132)\n",
      "For the second tuned SVM model over Portuguese data: \n",
      "Accuracy based on 10-fold cross validation is: 0.835 (+/- 0.095)\n"
     ]
    }
   ],
   "source": [
    "print(\"For the first tuned SVM model over Portuguese data: \")\n",
    "sp31 = find_accuracy(svm3, 10, Xpor, ypor)\n",
    "print(\"For the second tuned SVM model over Portuguese data: \")\n",
    "sp41 = find_accuracy(svm4, 10, Xpor, ypor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the 10-fold cv results, the second model is adopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8153846153846154\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.45      0.26      0.33        34\n",
      "       Pass       0.86      0.93      0.89       161\n",
      "\n",
      "avg / total       0.79      0.82      0.80       195\n",
      "\n",
      "Tuned Model Parameters: {'min_samples_leaf': 8, 'max_features': 12, 'max_depth': 19}\n",
      "Accuracy based on 5-fold cross validation is: 0.830 (+/- 0.044)\n"
     ]
    }
   ],
   "source": [
    "tree2 = Tree_Grid_Search(Xpor, ypor, dt1, ft1, mt1, rs=28)\n",
    "tp2 = find_accuracy(tree2, 5, Xpor, ypor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.50      0.12      0.19        26\n",
      "       Pass       0.88      0.98      0.93       169\n",
      "\n",
      "avg / total       0.83      0.87      0.83       195\n",
      "\n",
      "Tuned Model Parameters: {'n_estimators': 1000, 'min_samples_split': 5, 'max_features': 4, 'max_depth': 23, 'bootstrap': True}\n",
      "Accuracy based on 5-fold cross validation is: 0.840 (+/- 0.035)\n"
     ]
    }
   ],
   "source": [
    "rf2 = RF_Grid_Search(Xpor, ypor, nr1, dr1, fr1, mr1, rs=21)\n",
    "rp2 = find_accuracy(rf2, 5, Xpor, ypor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous sections have shown that all 6 final models all had a decent accuracy over testing data after trained over 70% of the data. Cross validations are performed to ensure that the models are not over fitting. To summarize the predictive performance of the the models, two metrics are used:\n",
    "\n",
    "1. The classfication report over precisions of each category are used to compare with the proportion of students in that category. This is necessary since both data sets are imbalanced data sets. And the precision of each category is crucial in showing the the classification model at least outperforms the raw blind classification.\n",
    "\n",
    "2. The accuracy based on 10-fold cross validation is summarized into a table for comparing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model precision for each level compared with actual proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"BMath p.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"BPortuguese p.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tables summarize the precisions of six final models for each level (namely Pass and Fail) of G3. All the precisions are above the baseline given by proportion, indicating all the classifiers perform better than blind classifier (i.e. blindly classifying students as \"Pass\" in math course, which would end up with a precision of 0.67. The worst performing model, RF in this case, still outperforms the blind classifier with a precision of 0.69.).\n",
    "\n",
    "These two tables are crucial since the two data sets are imbalanced. So accuracy alone is not sufficient to show performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model accuracy acquired via 5-fold cross validation over whole data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"Accuracy.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table summarizes the accuracy estimates of each model for each dataset given by a 5-fold cross validation over the whole dataset. \n",
    "\n",
    "As can be told row wise, SVM performs the best in Math case, and Random Forest performs the best in Portuguese case.\n",
    "\n",
    "The three methods all perform better in the Portuguese case, which is reasonable, since the training data size is larger, allowing the model to learn better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
